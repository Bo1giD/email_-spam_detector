# file: C:\Users\matth\AppData\Roaming\Python\Python313\site-packages\sklearn\feature_extraction\text.py
# hypothesis_version: 6.131.22

[1.0, '(?u)\\b\\w\\w+\\b', '<([^>]+)>', 'ASCII', 'CountVectorizer', 'ENGLISH_STOP_WORDS', 'HashingVectorizer', 'NFKD', 'TfidfTransformer', 'TfidfVectorizer', 'Vocabulary is empty', '\\s\\s+', '__iter__', '_stop_words_id', '_tfidf', 'alternate_sign', 'analyzer', 'ascii', 'binary', 'boolean', 'both', 'char', 'char_wb', 'clip', 'content', 'csc', 'csr', 'decode_error', 'dtype', 'encoding', 'english', 'error', 'file', 'filename', 'float32', 'float64', 'i', 'idf_', 'ignore', 'input', 'l1', 'l2', 'left', 'lowercase', 'max_df', 'max_features', 'min_df', 'n_features', 'ngram_range', 'no_validation', 'norm', 'preprocessor', 'raw_documents', 'rb', 'replace', 'smooth_idf', 'stop_words', 'strict', 'string', 'strip_accents', 'strip_accents_ascii', 'strip_tags', 'sublinear_tf', 'token_pattern', 'tokenizer', 'unicode', 'use_idf', 'utf-8', 'vocabulary', 'vocabulary_', 'word']